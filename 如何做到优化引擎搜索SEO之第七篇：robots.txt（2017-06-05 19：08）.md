前文：[《如何做到优化引擎搜索SEO（有HTML，关键字，Ajax，url，内容顺序等）》](http://blog.csdn.net/qq_2842405070/article/details/72782616)

英文原文来源：[clickhelp博客](https://clickhelp.co/clickhelp-blog/)

英文原文：[*Online Documentation and SEO. Part 7 - Robots.txt* ](https://clickhelp.co/clickhelp-blog/online-documentation-and-seo-part-7-robots/)

下文均为翻译+自己的注解和想法
<font color=darkgray>（所有ClickHelp打广告部分用浅灰色注解）</font>

-----------


**<font size="4">翻译：</font>**

　　通常，每个网站都有搜索引擎不应该索引的目录和页面。比如，印刷版本的网站页面，页面安全系统（注册、身份验证），可能还有目录管理员资源文件夹,各种技术文件夹。此外，网站管理员可能想给索引搜索引擎提供更多的信息。例如，sitemap.xml文件的位置。

　　所有这些任务都是通过robots.txt文件执行。这仅仅是一个文本文件的一个特定的格式，你把它放在您的网站上（到主目录），网络爬虫知道如何正确地索引网站内容。此文件格式完全规范，可在谷歌开发者门户网站找到。时，谷歌网站管理员工具提供确保你正确的创建文件，这个功能是在爬封锁网址段robots.txt文件分析工具。所以，如果你看到你的网站在搜索结果中显示出一些奇怪的页面，或标记为在搜索引擎您使用网站管理员工具索引，你可以很容易地解决这个问题通过创建一个robots.txt文件。有很多工具在互联网上，可以帮助您生成正确的文件内容。

　　请注意：robots.txt文件并不是一种保护敏感页面的方法。这只是一组网络爬虫会确保他们指数有用的内容，而不是服务页面。您限制在文件中的网页将保持直接URL访问，但不会被索引。
　　

　　**<font size="4">Robots.txt 和 在线文档</font>**
　　

　　当涉及到在线文档工具，或者只是在Web上发布文档的工具，也有一些页面，你希望不要被索引，以避免混乱的读者时，他们来到一个网页，不应该直接从搜索结果访问。这可能是登录页、错误页面、打印机友好版本的文档、文档属性页、用户配置文件等。
　　

　　<font color="darkgray">在ClickHelp，我们把这部分SEO一样，不应该被索引的网页被封闭在robots.txt文件，所以你不需要考虑这个。你可以尝试所有的好处我们的技术写作软件使用免费的clickhelp试验。</font>


**<font size="5">自己的想法：</font>**

>请注意：robots.txt文件并不是一种保护敏感页面的方法。这只是一组网络爬虫会确保他们指数有用的内容，而不是服务页面。您限制在文件中的网页将保持直接URL访问，但不会被索引。

对于这一段↑，什么叫保持直接URL访问，但不会被索引？怎么做？[方法在这：https://tieba.baidu.com/p/4875740900](https://tieba.baidu.com/p/4875740900)